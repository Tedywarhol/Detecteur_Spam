import pandas as pd
import re
import nltk
import pickle
import tkinter as tk
from tkinter import messagebox
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# T√©l√©chargement des stopwords
nltk.download('stopwords')


class SpamClassifier:
    """Classe principale pour la d√©tection de spam"""

    def __init__(self):
        """Initialise le classifieur avec les composants principaux"""
        self.model = None
        self.vectorizer = TfidfVectorizer()
        self.stop_words = set(stopwords.words('english'))
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None

    def load_data(self, file_path):
        """
        Charge les donn√©es √† partir d'un fichier CSV
        Args:
            file_path (str): Chemin vers le fichier CSV
        Returns:
            pd.DataFrame: DataFrame contenant les colonnes 'label' et 'text'
        """
        try:
            # Chargement des donn√©es avec encodage latin-1
            df = pd.read_csv(file_path, encoding='latin-1')[['v1', 'v2']]
            df.columns = ['label', 'text']  # Renommage des colonnes

            # Affichage d'informations sur les donn√©es
            print("\nAper√ßu des donn√©es :")
            print(df.head())

            print("\nDistribution des classes :")
            print(df['label'].value_counts())

            return df
        except Exception as e:
            print(f"Erreur lors du chargement des donn√©es: {e}")
            raise

    def clean_text(self, text):
        """
        Nettoie le texte en appliquant plusieurs transformations
        Args:
            text (str): Texte √† nettoyer
        Returns:
            str: Texte nettoy√©
        """
        try:
            # Conversion en minuscules
            text = text.lower()

            # Suppression de la ponctuation et des caract√®res sp√©ciaux
            text = re.sub(r'\W', ' ', text)

            # Suppression des chiffres
            text = re.sub(r'\d+', '', text)

            # Normalisation des espaces
            text = re.sub(r'\s+', ' ', text).strip()

            # Suppression des stopwords
            words = text.split()
            words = [word for word in words if word not in self.stop_words]

            return ' '.join(words)
        except Exception as e:
            print(f"Erreur lors du nettoyage du texte: {e}")
            return text

    def prepare_data(self, df):
        """
        Pr√©pare les donn√©es pour l'entra√Ænement
        Args:
            df (pd.DataFrame): DataFrame contenant les donn√©es brutes
        Returns:
            tuple: (X, y) matrices de features et labels
        """
        try:
            # Nettoyage du texte
            df['clean_text'] = df['text'].apply(self.clean_text)

            print("\nExemple de texte nettoy√© :")
            print(df[['text', 'clean_text']].head())

            # Encodage des labels (ham:0, spam:1)
            df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})

            # Vectorisation TF-IDF
            X = self.vectorizer.fit_transform(df['clean_text'])
            y = df['label_num']

            print("\nForme de la matrice TF-IDF :", X.shape)

            return X, y
        except Exception as e:
            print(f"Erreur lors de la pr√©paration des donn√©es: {e}")
            raise

    def split_data(self, X, y):
        """
        Divise les donn√©es en ensembles d'entra√Ænement et de test
        Args:
            X: Matrice de features
            y: Vecteur de labels
        """
        try:
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                X, y,
                test_size=0.2,
                random_state=42,
                stratify=y  # Conservation de la distribution des classes
            )

            print("\nR√©partition des donn√©es :")
            print(f"- Ensemble d'entra√Ænement: {self.X_train.shape[0]} exemples")
            print(f"- Ensemble de test: {self.X_test.shape[0]} exemples")
        except Exception as e:
            print(f"Erreur lors de la division des donn√©es: {e}")
            raise

    def train_model(self, optimize_hyperparams=True):
        """
        Entra√Æne le mod√®le avec possibilit√© d'optimisation
        Args:
            optimize_hyperparams (bool): Active l'optimisation des hyperparam√®tres
        Returns:
            float: Score de pr√©cision
        """
        try:
            if optimize_hyperparams:
                # Optimisation avec validation crois√©e
                parameters = {'alpha': [0.1, 0.5, 1.0, 1.5]}
                self.model = GridSearchCV(
                    MultinomialNB(),
                    parameters,
                    cv=5,  # 5-fold cross-validation
                    scoring='accuracy'
                )
                self.model.fit(self.X_train, self.y_train)

                print("\nüîé Meilleurs param√®tres trouv√©s :")
                print(self.model.best_params_)
            else:
                # Entra√Ænement standard
                self.model = MultinomialNB()
                self.model.fit(self.X_train, self.y_train)

            # √âvaluation
            return self.evaluate_model()
        except Exception as e:
            print(f"Erreur lors de l'entra√Ænement du mod√®le: {e}")
            raise

    def evaluate_model(self):
        """√âvalue les performances du mod√®le"""
        try:
            y_pred = self.model.predict(self.X_test)
            accuracy = accuracy_score(self.y_test, y_pred)

            print("\nüìä R√©sultats de l'√©valuation :")
            print(f"Pr√©cision globale: {accuracy:.4f}")

            print("\nüìù Rapport de classification :")
            print(classification_report(self.y_test, y_pred))

            print("\nüìâ Matrice de confusion :")
            print(confusion_matrix(self.y_test, y_pred))

            return accuracy
        except Exception as e:
            print(f"Erreur lors de l'√©valuation du mod√®le: {e}")
            raise

    def save_model(self, file_path):
        """
        Sauvegarde le mod√®le et le vectoriseur
        Args:
            file_path (str): Chemin du fichier de sauvegarde
        """
        try:
            with open(file_path, 'wb') as f:
                pickle.dump({
                    'model': self.model,
                    'vectorizer': self.vectorizer
                }, f)
            print(f"\nüíæ Mod√®le sauvegard√© dans {file_path}")
        except Exception as e:
            print(f"Erreur lors de la sauvegarde: {e}")
            raise

    def load_model(self, file_path):
        """
        Charge un mod√®le pr√©-entra√Æn√©
        Args:
            file_path (str): Chemin du fichier √† charger
        """
        try:
            with open(file_path, 'rb') as f:
                data = pickle.load(f)
                self.model = data['model']
                self.vectorizer = data['vectorizer']
            print(f"\nüîç Mod√®le charg√© depuis {file_path}")
        except Exception as e:
            print(f"Erreur lors du chargement: {e}")
            raise

    def predict(self, message):
        """
        Pr√©dit si un message est spam ou ham
        Args:
            message (str): Message √† classifier
        Returns:
            str: 'spam' ou 'ham'
        """
        try:
            if not self.model or not self.vectorizer:
                raise ValueError("Mod√®le non initialis√©. Veuillez d'abord entra√Æner ou charger un mod√®le.")

            # Pr√©traitement du texte
            cleaned_text = self.clean_text(message)

            # Vectorisation
            vectorized_text = self.vectorizer.transform([cleaned_text])

            # Pr√©diction
            prediction = self.model.predict(vectorized_text)[0]

            return 'spam' if prediction == 1 else 'ham'
        except Exception as e:
            print(f"Erreur lors de la pr√©diction: {e}")
            raise


class SpamClassifierUI:
    """Interface graphique pour le classifieur de spam"""

    def __init__(self, classifier):
        """
        Initialise l'interface
        Args:
            classifier (SpamClassifier): Instance du classifieur
        """
        self.classifier = classifier

        # Configuration de la fen√™tre principale
        self.window = tk.Tk()
        self.window.title("D√©tecteur de Spam")
        self.window.geometry("500x300")

        # Widgets
        self.create_widgets()

    def create_widgets(self):
        """Cr√©e et positionne les √©l√©ments de l'interface"""
        # Titre
        tk.Label(
            self.window,
            text="V√©rificateur de Spam SMS",
            font=("Arial", 14, "bold")
        ).pack(pady=10)

        # Zone de texte
        tk.Label(self.window, text="Entrez votre message :").pack()
        self.text_entry = tk.Text(self.window, height=8, width=50)
        self.text_entry.pack(padx=10, pady=5)

        # Bouton de v√©rification
        tk.Button(
            self.window,
            text="V√©rifier",
            command=self.check_spam,
            bg="#4CAF50",
            fg="white",
            font=("Arial", 10)
        ).pack(pady=10)

        # Label de r√©sultat
        self.result_label = tk.Label(
            self.window,
            text="",
            font=("Arial", 12, "bold")
        )
        self.result_label.pack()

    def check_spam(self):
        """Analyse le message et affiche le r√©sultat"""
        message = self.text_entry.get("1.0", tk.END).strip()

        if not message:
            messagebox.showwarning("Attention", "Veuillez entrer un message √† analyser")
            return

        try:
            result = self.classifier.predict(message)

            # Affichage color√© du r√©sultat
            if result == "spam":
                self.result_label.config(
                    text="R√©sultat: SPAM üö®",
                    fg="red"
                )
            else:
                self.result_label.config(
                    text="R√©sultat: HAM (legitime) ‚úÖ",
                    fg="green"
                )
        except Exception as e:
            messagebox.showerror("Erreur", f"Une erreur est survenue : {str(e)}")

    def run(self):
        """Lance l'application"""
        self.window.mainloop()


if __name__ == "__main__":
    # Initialisation du classifieur
    classifier = SpamClassifier()

    # 1. Charger les donn√©es
    df = classifier.load_data("spam.csv")

    # 2. Pr√©parer les donn√©es
    X, y = classifier.prepare_data(df)

    # 3. Diviser les donn√©es
    classifier.split_data(X, y)

    # 4. Entra√Æner le mod√®le (avec optimisation)
    classifier.train_model(optimize_hyperparams=True)

    # 5. Sauvegarder le mod√®le
    classifier.save_model("spam_classifier.pkl")

    # 7. Lancer l'interface
    app = SpamClassifierUI(classifier)
    app.run()
